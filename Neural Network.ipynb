{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Neural Network.ipynb","provenance":[],"authorship_tag":"ABX9TyPz17ZX9L9hVZnMe3Veb4Ky"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"WgbhC3x9UaYA"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yJWx_uB8ZEAv"},"source":["def get_data_loader(training=True):\n","  custom_transform= transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.1307,), (0.3081,))\n","        ])\n","  if training:\n","    dataset = datasets.MNIST('./data', train=training, transform=custom_transform, download=True)  \n","    return torch.utils.data.DataLoader(dataset, batch_size = 50, shuffle = True)\n","  else:\n","    dataset = datasets.MNIST('./data', train=training, transform=custom_transform, download=True)  \n","    return torch.utils.data.DataLoader(dataset, batch_size = 50)\n","  \n","\n","train_loader = get_data_loader()\n","print(type(train_loader))\n","print(train_loader.dataset)\n","test_loader = get_data_loader(False)\n","print(test_loader.dataset)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"lkaxRcf1Rbwp"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zDkp8GDovl5d"},"source":["def build_model():\n","  mnistnn = nn.Sequential(\n","    nn.Flatten(),\n","    nn.Linear(784, 128),\n","    # second arg is the number of nodes ... because each node will have only one output be default \n","    # only when u add another layer, the outputs will increase\n","    nn.ReLU(),\n","    nn.Linear(128, 64),\n","    nn.ReLU(),\n","    nn.Linear(64, 10)\n","    )\n","  return mnistnn\n","\n","# print(model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W97UpZHMjtMb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636041596906,"user_tz":300,"elapsed":53868,"user":{"displayName":"Harshith G","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgY6aU4wpM2iE-A7c6VI-hYQQLok9DEdETzVP4Mpw=s64","userId":"09663176884852901688"}},"outputId":"0ba9f114-90a2-4c12-8bfd-d3fa398482f7"},"source":["model = build_model()\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","def train_model(model, train_loader, criterion, T):\n","  \n","  model.train()\n","  opt = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","\n","  for epoch in range(T): \n","\n","      running_loss = 0.0\n","      correct = 0\n","      total = 0 \n","\n","      for i, data in enumerate(train_loader, 0):\n","          inputs, labels = data\n","          opt.zero_grad()\n","          outputs = model(inputs)\n","          loss = criterion(outputs, labels)\n","          _, predicted = torch.max(outputs.data, 1)\n","          total += labels.size(0)\n","          correct += (predicted == labels).sum().item()\n","          loss.backward() \n","          opt.step()\n","          running_loss += loss.item()*train_loader.batch_size\n","\n","      print(\"​Train Epoch: \"+str(epoch)+ \"   Accuracy: \" + str(correct) + \"/\" + str(total) + \"(\" + \"{:.2f}%\".format((100 * correct / total)) + \")\"+ \" Loss: \"+ \"{:.3f}\".format(running_loss/total))\n","        \n","  model.train(mode=False)\n","\n","train_model(model, train_loader, criterion, T = 5)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["​Train Epoch: 0   Accuracy: 48244/60000(80.41%) Loss: 0.759\n","​Train Epoch: 1   Accuracy: 54843/60000(91.41%) Loss: 0.295\n","​Train Epoch: 2   Accuracy: 55887/60000(93.14%) Loss: 0.236\n","​Train Epoch: 3   Accuracy: 56587/60000(94.31%) Loss: 0.197\n","​Train Epoch: 4   Accuracy: 57081/60000(95.14%) Loss: 0.168\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OfBq-IXAueey","executionInfo":{"status":"ok","timestamp":1636041608516,"user_tz":300,"elapsed":1891,"user":{"displayName":"Harshith G","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgY6aU4wpM2iE-A7c6VI-hYQQLok9DEdETzVP4Mpw=s64","userId":"09663176884852901688"}},"outputId":"306879fc-4ed3-4339-c1c5-612dbf29c810"},"source":["def evaluate_model(model, test_loader, criterion, show_loss = True):\n","  \n","  model.eval()\n","\n","  correct = 0\n","  total = 0\n","  running_loss = 0\n","\n","  with torch.no_grad():\n","      for data in test_loader:\n","          inputs, labels = data\n","          outputs = model(inputs)\n","\n","          if show_loss:\n","            loss = criterion(outputs, labels)\n","            running_loss += loss.item()*test_loader.batch_size\n","\n","          _, predicted = torch.max(outputs.data, 1)\n","          total += labels.size(0)\n","          correct += (predicted == labels).sum().item()\n","\n","  if show_loss:\n","    print('Average loss: '+\"{:.4f}\".format((running_loss / total)))\n","    \n","  print(\"Accuracy: \" + \"{:.2f}%\".format((100 * correct/total)))\n","\n","evaluate_model(model, test_loader, criterion)\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average loss: 0.1550\n","Accuracy: 95.19%\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HUbY7wxDFWet","executionInfo":{"status":"ok","timestamp":1636041616256,"user_tz":300,"elapsed":208,"user":{"displayName":"Harshith G","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgY6aU4wpM2iE-A7c6VI-hYQQLok9DEdETzVP4Mpw=s64","userId":"09663176884852901688"}},"outputId":"23882ebc-d06f-4038-ea3e-8261fb08a2e0"},"source":["def predict_label(model, test_images, index):\n","\n","  class_names = ['zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine']\n","\n","  logit = model(test_images[index])\n","  sm = F.softmax(logit, dim=1)\n","  values,indices = sm.topk(3)\n","\n","  for idx,val in zip(indices[0], values[0]):\n","    percentage = \"{:.2%}\".format(val.item())\n","    print(class_names[idx]+\":\", percentage)\n","\n","for data in test_loader:\n","  inputs, labels = data\n","  pred_set = inputs\n","  print(labels)\n","  break\n","\n","# print(pred_set)\n","# print(torch.__version__)\n","predict_label(model, pred_set, 3)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4, 9, 6, 6, 5,\n","        4, 0, 7, 4, 0, 1, 3, 1, 3, 4, 7, 2, 7, 1, 2, 1, 1, 7, 4, 2, 3, 5, 1, 2,\n","        4, 4])\n","zero: 99.97%\n","two: 0.01%\n","nine: 0.00%\n"]}]}]}